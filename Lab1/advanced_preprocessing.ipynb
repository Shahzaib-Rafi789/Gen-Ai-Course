{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    Age   Salary\n",
      "0  25.0  50000.0\n",
      "1  30.0      NaN\n",
      "2   NaN  60000.0\n",
      "3  35.0  70000.0\n",
      "\n",
      "DataFrame after Mean Imputation:\n",
      "    Age   Salary\n",
      "0  25.0  50000.0\n",
      "1  30.0  60000.0\n",
      "2  30.0  60000.0\n",
      "3  35.0  70000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with missing values\n",
    "data = {\n",
    "    'Age': [25, 30, np.nan, 35],\n",
    "    'Salary': [50000, np.nan, 60000, 70000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Impute missing values with mean\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "df['Salary'].fillna(df['Salary'].mean(), inplace=True)\n",
    "\n",
    "# Display the DataFrame after imputation\n",
    "print(\"\\nDataFrame after Mean Imputation:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging\n",
    "Process of assigning a part of speech to each word in a sentence. \n",
    "Common POS tags include nouns, verbs, adjectives, adverbs etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NLTK', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('leading', 'VBG'), ('platform', 'NN'), ('for', 'IN'), ('building', 'VBG'), ('Python', 'NNP'), ('programs', 'NNS'), ('to', 'TO'), ('work', 'VB'), ('with', 'IN'), ('human', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
    "\n",
    "words = nltk.word_tokenize(text)\n",
    "\n",
    "pos_tags_nltk = nltk.pos_tag(words)\n",
    "\n",
    "print(pos_tags_nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spaCy', 'INTJ', 'UH'), ('is', 'AUX', 'VBZ'), ('an', 'DET', 'DT'), ('open', 'ADJ', 'JJ'), ('-', 'PUNCT', 'HYPH'), ('source', 'NOUN', 'NN'), ('library', 'NOUN', 'NN'), ('for', 'ADP', 'IN'), ('advanced', 'ADJ', 'JJ'), ('Natural', 'PROPN', 'NNP'), ('Language', 'PROPN', 'NNP'), ('Processing', 'PROPN', 'NNP'), ('in', 'ADP', 'IN'), ('Python', 'PROPN', 'NNP'), ('.', 'PUNCT', '.')]\n"
     ]
    }
   ],
   "source": [
    "text = \"spaCy is an open-source library for advanced Natural Language Processing in Python.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "pos_tags_spacy = [(token.text, token.pos_, token.tag_) for token in doc]\n",
    "print(pos_tags_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "Chunking (or shallow parsing) takes the POS-tagged words and groups them into larger units such as noun phrases (NP), verb phrases (VP), etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  NLTK/NNP\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  leading/VBG\n",
      "  (NP platform/NN)\n",
      "  for/IN\n",
      "  building/VBG\n",
      "  Python/NNP\n",
      "  programs/NNS\n",
      "  to/TO\n",
      "  work/VB\n",
      "  with/IN\n",
      "  (NP human/JJ language/NN)\n",
      "  data/NNS\n",
      "  ./.)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define a chunk grammar\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "# Create a chunk parser\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "# Parse the sentence to get chunks\n",
    "tree = cp.parse(pos_tags_nltk)\n",
    "\n",
    "# Print the chunk tree\n",
    "print(tree)\n",
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: The quick brown fox, Root Text: fox, Root Dep: nsubj, Root Head Text: jumps\n",
      "Chunk: the lazy dog, Root Text: dog, Root Dep: pobj, Root Head Text: over\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract and print noun phrases (NPs)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(f\"Chunk: {chunk.text}, Root Text: {chunk.root.text}, Root Dep: {chunk.root.dep_}, Root Head Text: {chunk.root.head.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding\n",
    "Text embedding is the process of converting text into numerical vectors that can be used by machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12400028  0.13036624  0.10375945  0.06526087 -0.01802809 -0.10003968\n",
      "  0.11321629  0.31538635 -0.13024324 -0.17027508  0.0204285  -0.18054175\n",
      " -0.0557485   0.09536618  0.19326502 -0.06983682 -0.00352094 -0.19092159\n",
      " -0.14799626 -0.2168642   0.14356326  0.11956564  0.297104    0.1323912\n",
      " -0.08210941 -0.04149396 -0.24066937 -0.09875017  0.01496314  0.13318369\n",
      "  0.19893812 -0.1008561   0.18726346 -0.22913675 -0.01513384  0.18489641\n",
      " -0.04390021  0.06190151 -0.1545404  -0.04611038  0.05350776 -0.19813696\n",
      " -0.0088488   0.04358754  0.10623358  0.01677817 -0.06863146  0.01468717\n",
      "  0.04589223  0.10192411  0.08500671 -0.1329406  -0.1591965  -0.04625204\n",
      " -0.00442203 -0.07751082  0.11744513 -0.00382323 -0.03493624  0.06209708\n",
      " -0.03585383  0.15543246  0.00891487 -0.03393736 -0.1531956   0.15026395\n",
      "  0.17832513  0.18629818 -0.29575554  0.27191487  0.10920096  0.06182568\n",
      "  0.20571443 -0.04702065  0.11151341  0.03914363  0.00972655  0.10746009\n",
      "  0.03979657 -0.04641774 -0.1034132   0.10573719 -0.05255026  0.11245462\n",
      " -0.13059132 -0.01899729  0.03430163  0.1028239   0.15234023  0.02857955\n",
      "  0.23433135 -0.12134096 -0.05934972  0.00528687  0.18088579  0.0752364\n",
      "  0.06587455 -0.17623813 -0.01606193 -0.02544095]\n",
      "[('Birmingham', 0.9641707539558411), ('master', 0.9560958743095398), ('graceful', 0.9525282382965088), ('rousing', 0.9524543881416321), ('Vienna', 0.9506645798683167)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Load the Brown corpus\n",
    "sentences = brown.sents()\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "# Example usage: Get the vector for the word 'king'\n",
    "vector = model.wv['king']\n",
    "print(vector)\n",
    "\n",
    "# Find most similar words\n",
    "similar_words = model.wv.most_similar('king', topn=5)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.8038062  -0.57184035 -1.0615969   0.1685325  -0.73480105 -0.07565041\n",
      "  2.47716     0.34800076 -0.14537281  0.05508129  0.9790832  -1.0621793\n",
      " -0.90454197  0.63134384 -0.16790569  0.12966211 -0.7590473  -1.0194731\n",
      "  1.8497288   0.68561244  0.42840576  1.9528611   0.71009314 -0.49444747\n",
      "  0.15484339  1.1637604   0.32334328  1.9428613  -0.4038114  -0.40275377\n",
      "  0.03499427 -0.2542291   0.72335136 -0.19704051 -0.38484254 -2.0028517\n",
      " -0.04508871  0.602212    0.4824512   0.08982205 -0.30942625  0.5462789\n",
      " -0.3974073   0.15101105 -0.75147295 -1.0158409  -1.3755283   1.5071571\n",
      "  0.07189959  0.38855618  0.22438756  0.430369    0.81013995 -1.1247113\n",
      " -0.4688068  -1.1177742   1.0850023   0.25971973  0.28847817 -0.87373275\n",
      " -0.9647601  -0.4774765   0.7437953  -0.5322264   0.4202554   0.10787368\n",
      " -0.26062754  0.47333872  0.49753362 -2.0549963   0.1926519   0.16442215\n",
      "  1.0940242  -0.5006186  -0.28406495 -0.84961617  0.00315695  0.35117477\n",
      "  0.46972567 -1.1229045  -0.2193472  -0.6019075  -1.9369872  -1.1479326\n",
      "  0.06317723  0.36457014  1.0063617  -0.06738757 -0.89169693  1.8681461\n",
      " -1.5638493   0.4468745   1.8851739   0.73967326  1.1027694   0.7580921 ]\n",
      "Similarity between 'king' and 'queen': 0.5099376221161971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PMLS\\AppData\\Local\\Temp\\ipykernel_13404\\1056760107.py:14: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = text1.similarity(text2)\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "text = \"king\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Get the vector for the text\n",
    "vector = doc.vector\n",
    "print(vector)\n",
    "\n",
    "# Finding similarities\n",
    "text1 = nlp(\"king\")\n",
    "text2 = nlp(\"queen\")\n",
    "similarity = text1.similarity(text2)\n",
    "print(f\"Similarity between 'king' and 'queen': {similarity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
